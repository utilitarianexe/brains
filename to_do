unsorted issues
  validate warp fix and reprofile
  whats preventing 1 from firing an output
  record results to file
  import full mnist set
  put nmist in readme with learned model
  is it ok to include mnist data in our repo
  move to rust
      make the cell membrane in rust
      make some tests for it
      connect it up to simple model
      make a script to auto compile everything
      make the whole model in rust
      
  decuple brain and env from display
  does inhibition mean we need higher max strengths
  too much  repeated code in main
  multiple simultanious runs
  memory leak in UI
  wtf step size

  network.py needs refactored
    too much ui
    lock_inhibition_strength probably uneeded

  display prameters for a cell when you clikc particularly(s_tag_decay, last update amount)
  why don't we just totaly artificially normalize fire rates for input
    give them a target fire rate
    apply env input to one synapse
    apply a random input to another
    use input balancing on those

  should the inhibition property be on Layer or LayerConection
  display fire rate on selected cells
  show a grid of cells by input totals ect rather than each synapse or clicking each cell
  faster UI
  should stdp be scaled by strength
  combine pyplot and pygame
  clean out output balance(parameterize, test, ect)
  porportion award
  track progress porportionally
  print what did fire to screen
  better way to handle running out of images
  nmist and handwriting too much copy paste
  layer based diagnostics like total input strength
  model based error condition tracking(double fires, not resetting by the time of epoch)
  remove warp fudge
  paramaterize fire rate adaptation
  delays make sense in env
  cell_definition.x_input_position don't like the default 0
  need a world class to avoid simple_model repeating the step loop in every function
  strength of stimuli is a magic number in env
  manual cell definition is ugly again
  stop with the real step check repeated everywhere
  correct cell fired is a bad name
  dumb world vs env cli thing
  default to long file x o file
  on import why does it take some time to stabalize
  dont run longer than we have images
  unit test for learning on simple network
  need a seperate epoch length/delay for envs
  use pattern matching and type hints

refactoring
  take out dopamine cut off and warp timer parameter
  environmnet majic numbers and copy paste code(should make base class)
  hack to reset s_tag s tag stag
  main file is too long and needs tests
  switch from "model" to "brain"
  use dacite package instead of __post__init__ bs
  test parameters confusion
  simple_model is a bad name
  move parameters out of model file and networks out of network file
  clean up environment to allow for better tests without putting the test env in its own class
  also better tests for environment
  remove to do type comments
  document
  get rid of magic numbers(most at least moved to class definitions)
  follow python style guide
  reorder parameters
  simple_model output is a mess
  get example and spirit working with video, export, import, and pyplot
  arguably export should be a type of display
  I don't like how we attach cells to synapses in the simple model
  use private consistantly the _ thing
  simple_model class could be split in 3

advertising
  what else is out there
  who would want this

installation/updates
  auto run tests on submit

new funcitonality
  cells
    output balancing
    try other equation for fire rate balancing average = average * (1-alpha) + real * alpha

  display
    bug stacking inhibitory layers
    layers_from_definitons in network.py is doing too much ui work
    in pygame display labels for input and wins
    accuracy graph
    red should be positive green negative
    pause button
    click on cells to see cell info
    adjust parameters without restarting
    detect screen size
    attach to unreal engine or something
    UI to build network
    should try to get input hitting faster so users see it earlier

  management
    figure out what images we are failing on
    periodically save brains during run
    add a ./run_tests file that runs a bunch of complete runs
    add an adder environment as a mid level task
    make a plotting tool with our basic equations in it
      like how much does s_tag decay in an epoch
    should be a model level synapse connection strength that is then scaled per synapse
    apply the complex environment to a simple model
    elf grid specs
    run neurons in compliled language

  create a one variable cell type example
    no input current variable
    cell just needs enough input spikes in short enough window to spike
    only one timestep delay betwenn precell spike and post cell spike

think about
  try handwriting with one less layer
  what distribution should we use for noise
  get more backround on simulation generally(really need to retake calc)
  connecitons strengths should not just be random at the start but maybe also randomly change a bit?
  step sizes
  resettting input connections
  multiple inhibit layers